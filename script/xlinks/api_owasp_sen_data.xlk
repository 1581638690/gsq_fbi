#LastModifyDate:　2024-01-09T11:37:20    Author:   qh
#LastModifyDate:　2024-01-09T10:25:43    Author:   rzc
#LastModifyDate:　2024-01-08T09:34:20    Author:   superFBI
#LastModifyDate:　2024-01-06T16:20:05    Author:   superFBI
#LastModifyDate:　2024-01-06T15:43:17    Author:   superFBI
#LastModifyDate:　2024-01-06T13:58:03    Author:   superFBI
#LastModifyDate:　2024-01-05T11:09:39.315295    Author:   superFBI
#LastModifyDate:　2023-12-28T09:24:55.743731    Author:   superFBI
#LastModifyDate:　2023-12-27T15:19:25.760687    Author:   superFBI
#LastModifyDate:　2023-12-27T10:17:14.271774    Author:   superFBI
#LastModifyDate:　2023-12-20T11:26:46.133609    Author:   superFBI
#xlink脚本
#file: api_owasp_sen_data.xlk
#name: 
#描述： 



#初始化
init => {
	stream["meta_name"] = "OWASP_数据流动敏感数据"
	stream["meta_desc"] = "处理弱点和数据流动中有关敏感数据的数据和api19-3，api19-7-5，api19-8"
	a = load_ssdb_kv("setting")
	stream["redis_link"] = a["kfk"]["redis"]["addr_r"]
	stream["link"] = a["kfk"]["origin"]["link"]
	stream["topic"] = a["kfk"]["origin"]["topic"]
	stream["reset"] = a["kfk"]["origin"]["reset"]
	#stream["source"]= {"link":"127.0.0.1:16379","topic":"api_visit","redis":"pubsub"}
	#stream["source"]= {"link":stream["link"],"topic":stream["topic"],"group":"API19SEN","start-0":stream["reset"]}
	#stream["source"]= {"link":stream["redis_link"]+":6382","topic":"api_visit1","redis":"pubsub"}
	#stream["source"]= {"unix_udp":"/tmp/owp_sen_data"}
	stream["source"] = {"shm_name":"httpub","count":8}
	stream["redis"]={"host":stream["redis_link"],"port":"6382"}
	#kfk
	#stream["CKH"] = CKH_Client(host="127.0.0.1",port=19000,user="default",password="client")
	stream["ipdb"] = IPIPDatabase( '/opt/openfbi/workspace/ipdb.datx')
	#自定义的统计变量
	stream["count"] = 0
	stream["count_10"] = 0
	s = load_ssdb_kv("qh_owasp")
	stream["API19_3"] = s["setting"]["API19-3"]
	stream["API19_8"] = s["setting"]["API19-8"]
	#自定义的统计变量
	b = load_ssdb_kv("qh_send")["sends"].split(',')
	if "api_sen" in b:
		stream["sends"] = 1
	else:
		stream["sends"] = 0
	if "api_sent" in b:
		stream["sends2"] = 1
	else:
		stream["sends2"] = 0
	if "api_senm" in b:
		stream["sends3"] = 1
	else:
		stream["sends3"] = 0
	set_param("l",stream["link"])
	if "api_model" in b:
		set_param("m","1")
	else:
		set_param("m","0")
	stream["st"]["st_10s"]={"times":10,"fun":"print10"}
	stream["stw"]["stw_flow"]={"times":10,"fun":"flow"}
	stream["stw"]["stw_flow2"]={"times":90,"fun":"flow2"}
	stream["stw"]["stw_flow3"]={"times":100,"fun":"flow3"}
	#stream["st"]["st_60s"]={"times":60,"fun":"send60"}
	s = load_ssdb_kv("monitor_url_xlk")["data"]
	stream["monitor_url"] = []
	for item in s:
		stream["monitor_url"].append(item[0])
	c = load_ssdb_kv("model_config")
	stream["all_combo"] = c["setting"]["switch"]["all_combo"]
}


#事件处理函数
events => {
	#hp = ujson.loads(o["httpjson"])
	#http = hp.get("http")
	#debug_on(1)
	#return o
	data_type=o.get("data_type")
	if data_type == "XML" or data_type == "数据文件" or data_type == "JSON" or data_type == "动态脚本":
		app = o.get("app")
		api = o.get("url_c")
		http=o.get("http")
		k = iso_to_timestamp(o["timestamp"])
		timestamp = iso_to_datetime(o["timestamp"])
		parameter = o.get("parameter")
		srcip=o.get("src_ip")
		#Delete 注释 by rzc on 2023-04-26 17:32:50
		if http:
			request_headers = http.get('request_headers', '')
		else:
			request_headers=""
		request_body=o.get("http_request_body","")
		response_body=o.get("http_response_body","")
		ID=o.get("id")
		api_8 = api19_8(str(timestamp),parameter,request_headers,request_body,stream["API19_8"], stream["API19_3"])
		total_info=o.get("total_info")
		datas,lk,length,msg=sen_data(srcip,str(timestamp),total_info,request_body,response_body,ID)
		if api_8:
			for data in api_8:
				e = clone_event(o)
				e["app"] = app
				e["api"] = api
				e["type"] = data["type"]
				e["more"] = ujson.dumps(data["more"])
				push_stw("stw_flow",k,e)
				#to_redis("owasp_data",o)
		# 敏感数据访问数据波动过大
		if length >0:
			e = clone_event(o)
			e["app"] =  app
			e["api"] =  api
			e["type"] = "API19-3-4"
			e["num"] = length
			e["time"] = str(timestamp)
			push_stw("stw_flow2",k,e)
			if o.get("url_c") in stream["monitor_url"] or stream["all_combo"]:
				#下面模型用
				e['srcip'] = srcip
				e['srcport'] = o.get('src_port')
				e['url_a'] = o.get('url')
				e['account'] = o.get('account')
				e['real_ip'] = o.get('realip')
				e["id"] = xlink_uuid(1)
				e['proof'] = o.get('id')
				push_stw("stw_flow3",k,e)
			#to_redis("owasp_data",o)
		# 则判断是否是内网访问
		ip_is = ip_lookup(srcip)
		if ip_is and datas:
			#printf("message",message)
			e = clone_event(o)
			e["app"] =  app
			e["api"] =  api
			e["type"] = "API19-7-5"
			e["more"] = ujson.dumps(datas,ensure_ascii=False)

			push_stw("stw_flow",k,e)
			#to_redis("owasp_data",o)
		#数据量过大
		if stream["API19_3"]["API19-3-1"] <= length and datas:
			e = clone_event(o)
			e["app"] =  app
			e["api"] =  api
			e["type"] = "API19-3-1"
			e["more"] =  ujson.dumps(datas,ensure_ascii=False)

			push_stw("stw_flow",k,e)
			#to_redis("owasp_data",o)
		#数据类型过多
		if stream["API19_3"]["API19-3-2"] <= lk and datas:
			e = clone_event(o)
			e["app"] =  app
			e["api"] =  api
			e["type"] = "API19-3-2"
			datas.pop('敏感数据', None)
			e["more"] = ujson.dumps(datas,ensure_ascii=False)

			push_stw("stw_flow",k,e)
			#to_redis("owasp_data",o)
}

#系统定时函数
print10 => {
	c = load_ssdb_kv("model_config")
	stream["all_combo"] = c["setting"]["switch"]["all_combo"]
	s = load_ssdb_kv("monitor_url_xlk")["data"]
	stream["monitor_url"] = []
	for item in s:
		stream["monitor_url"].append(item[0])
	s = load_ssdb_kv("qh_owasp")
	stream["API19_3"] = s["setting"]["API19-3"]
	stream["API19_8"] = s["setting"]["API19-8"]
	b = load_ssdb_kv("qh_send")["sends"].split(',')
	if "api_sen" in b:
		stream["sends"] = 1
	else:
		stream["sends"] = 0
	if "api_sent" in b:
		stream["sends2"] = 1
	else:
		stream["sends2"] = 0
	if "api_senm" in b:
		stream["sends3"] = 1
	else:
		stream["sends3"] = 0
	set_param("l",stream["link"])
	if "api_model" in b:
		set_param("m","1")
	else:
		set_param("m","0")
	#push_arrays_to_df(table,"flow")
	#store_ckh(pools["ckh"],"flow")
	#save()
}
flow2 => stw{
	a = load ssdb by ssdb0 with qh_owasp as json
	b = jaas a by a["setting"]["API19-3"]["API19-3-4"] as sdf
	flow2 = group df by api agg  num:median
	flow2 = @udf flow2 by udf0.df_reset_index
	flow2 = join df,flow2 by api,api
	flow2 = add num_mad by abs(flow2["num"]-flow2["num_median"])/flow2["num_median"]
	flow2 = loc flow2 by api,num_mad
	
	#flow2 = group df by api agg num:mad
	#flow2 = @udf flow2 by udf0.df_reset_index
	flow2 = filter flow2 by num_mad > $b
	flow2 = join flow2,df by api,api with
	flow2 = distinct flow2 by api
	alter flow2.num_mad as str
	flow2 = add more with ('{"敏感数据平均极差过大":"超过限制","波动平均极差为":"' + flow2["num_mad"] + '", "访问时间":"' + flow2["time"] + '"}')
	flow2 = loc flow2 drop num,time,num_mad,url_a,account,real_ip,id,srcport,srcip,uid
	flow2 = @udf flow2 by udf0.df_set with (state='待确认')
	a = load db by mysql1 with select api,type,id,state states,length lengths from api19_risk where type = 'API19-3-4'
	flow2 = join flow2,a by [api,type],[api,type] with left
	flow2 = @udf flow2 by udf0.df_fillna with 0
	flow2 = @udf flow2 by udf0.df_set_index with id
	flow21 = filter flow2 by index == 0 and states !='忽略'
	flow21 = loc flow21 drop states,lengths
	@udf flow21 by CRUD.save_table with (mysql1,api19_risk)
	flow22 = filter flow2 by index != 0 and states !='忽略'
	alter API192.length as int
	alter API192.lengths as int
	flow22 = @udf flow22 by udf0.df_row_lambda with x: x["length"] if x["length"] > x["lengths"] else x["lengths"]
	flow22 = loc flow22 drop first_time,state,states,length,lengths
	flow22= rename flow22 as ('lambda1':'length')
	# 保存
	@udf flow22 by CRUD.save_table with (mysql1,api19_risk,more)

	
	drop df
	drop flow2
	drop flow21
	drop flow22
}
flow3 => stw{
	src_model = load ssdb by ssdb0 with srcip_model_xlk
	model_config = load ssdb by ssdb0 with model_config as json
	on = jaas model_config by model_config["setting"]["switch"]["model3"] as sdf
	if "$on" == "true" with """
		model3 = loc df drop (first_time,state,method,length,type,last_time,num_mad,more)
		rename model3 as ("time":"timestamp","dest_ip":"dstip","dest_port":"dstport","api":"url")
		model3 = join src_model,model3 by srcip,srcip
	""" else """
		model3 = @udf udf0.new_df
	"""
	monitor_url = load ssdb by ssdb0 with monitor_url_xlk
	model3 = join monitor_url,model3 by url,url
	wl = jaas model_config by model_config["setting"]["model3"]["whitelist"]
	wl = @udf wl by FBI.json2df
	wl = @udf wl by udf0.df_reset_index
	wls = @udf udf0.new_df
	foreach wl run """
		wl1 = filter wl by (index == @idx)
		wl1 = @udf wl1 by model.dropem
		wl1 = loc wl1 drop index
		wl2 = @udf wl1,model3 by model.join2
		wls = union (wls,wl2)
	""" with (idx=$1)
	if wls.index.size == 0 with """
		wls = limit model3 by 500000
	"""
	wls = distinct wls by id
	sens_mean = load ssdb by ssdb0 with sens_mean
	b = jaas model_config by model_config["setting"]["model3"]["mean"] as sdf
	sens_mean = add mean with (sens_mean["mean"]*$b)
	model3 = join wls,sens_mean by url,url with left
	model3 = @udf model3 by udf0.df_fillna with 0
	model3 = filter model3 by (num > mean)
	alter model3.num as str
	alter model3.mean as str
	model3 = add message with ('终端“' + model3["srcip"] + '访问接口' + model3["url"] + '返回数据波动超过限制，波动值：' + model3["num"] + '，月平均值：' + model3["mean"])
	b = @sdf sys_str with ($b,strip())
	#model33 = limit model3 by 10000
	proofs = @udf udf0.new_df
	model3 = loc model3 by (srcip,url,num,mean,dstip,dstport,app,url,timestamp,srcport,url_a,account,real_ip,id,proof,mean,message)
	foreach model3 run """
		f = filter model3 by (srcip == "@srcip" and url == "@url")
		c = loc f by timestamp,proof
		rename c as ("proof":"suid")
		d = @udf c by model.proof3 with @srcip,@url,@num,@mean,$b
		proofs = union (proofs,d)
	""" with (url=$2,srcip=$1,num=$3,mean=$4)
	model3 = loc model3 drop (mean,num)
	proofs = @udf proofs by udf0.df_reset_index
	proofs = loc proofs drop index
	model3 = @udf model3 by udf0.df_fillna
	model3 = @udf model3 by udf0.df_reset_index
	model3 = loc model3 drop index
	model3 = join model3,proofs by index,index with left
	alter model3.timestamp as datetime64
	model3 = add type with (3)
	model3 = add level with (2)
	model3 = add desc with ("超出限定值视为波动过大，此访问行为判定为有风险")
	store model3 to ckh by ckh with api_model
	#"""
	if "@mm" == "1" with """
		define kfka as "@l"
		k = @udf KFK.df_link with kfka
		alter model3.timestamp as str
		model3 = add event_type by ("model")
		a = @udf model3 by KFK.fast_store with kfka,api_send
	"""
	drop model3
	drop model33
	drop proofs
	drop wl
	drop wl1
	drop wl2
	drop wls
	drop sens_mean
	drop src_model
	drop b
	drop a
	drop monitor_url
	drop df
}
flow => stw{
	size = eval df by (index.size)
	if $size > 0 with """
		# 去重
		#df.more=str more by replace("\\","")
		API19 = distinct df by (api,type)
		API19 = @udf API19 by udf0.df_set with (state='待确认')
		a = load db by mysql1 with select api,type,id,state states,length lengths from api19_risk where type = 'API19-3-1' or type = 'API19-3-2' or type = 'API19-3-3' or type = 'API19-7-5' or type like 'API19-8%%'
		API19 = join API19,a by [api,type],[api,type] with left
		#获取只对id将nan值 存为0 
		
		API19 = @udf API19 by udf0.df_fillna with 0
		#API19.id=lambda id by x:0 if not x else x 
		API19 = @udf API19 by udf0.df_set_index with id
		API191 = filter API19 by index == 0 and states !='忽略'
		API191 = loc API191 drop states,lengths
		###
		@udf API191 by CRUD.save_table with (mysql1,api19_risk)
		API192 = filter API19 by index != 0 and states !='忽略'
		alter API192.length as int
		alter API192.lengths as int
		API192 = @udf API192 by udf0.df_row_lambda with x: x["length"] if x["length"] > x["lengths"] else x["lengths"]
		API193 = loc API192 drop first_time,state,states,length,lengths
		API193= rename API193 as ('lambda1':'length')
		#API192.request_body=lambda request_body by x:x if x!=0 else '{}'
		#API192.response_body=lambda response_body by x:x if x!=0 else '{}'
		# 保存
		@udf API193 by CRUD.save_table with (mysql1,api19_risk,more)
		API194 = loc API192 by last_time
		@udf API194 by CRUD.save_table with (mysql1,api19_risk)
		drop df
		drop API19
		drop API191
		drop API192
		drop API193
		drop API194
		drop a
	"""
}
sen_data =>(srcip,time,total_info,request_body,response_body,ID){
	datas = {}
	infos = {}
	keys = {}
	message=[]
	#判断是响应体大于还是请求体大于
	for pos,info in total_info.items():
		if len(info)>=3:
			message.append(pos)
			for key,value in info.items():
				if value:
				#if value and value not in err_name:
					if infos.get(key):
						infos[key].extend(value)
					else:
						infos[key] = value
					if keys.get(key):
						keys[key] += len(value)
					else:
						keys[key] = len(value)
	msg={}
	for i in message:
		if i=="请求体":
			msg["请求体"]=request_body
		elif i=="响应体":
			msg["响应体"]=response_body
	#Delete 注释 by superFBI on 2023-05-10 14:44:34
#if msg:
#		msg=ujson.dumps(msg,ensure_ascii=False).replace("\\","")
#	else:
		#msg=""
	if keys and infos:
		#datas["原始ID"]=ID
		datas["源端IP"] = srcip
		datas["访问时间"] = time
		datas["敏感数据类型及数量"] = keys
		datas["敏感数据"] = infos
		datas["证据样例"]=msg
		
	lk = 0
	li = 0
	for a in keys.values():
		li += a
	for a in infos.values():
		lk += 1
	return datas,lk,li,msg
}
clone_event =>(o){
	e = {
		"first_time": str(iso_to_datetime(o["timestamp"])),
		"last_time": str(iso_to_datetime(o["timestamp"])),
		"dest_ip": o.get("dest_ip"),
		"dest_port": o.get("dest_port"),
		"method": o.get("http").get("http_method", ""),
		"state": "待确认",
		"length": o.get("http").get('length', 0)
	}
	return e
}
ip_lookup => (ip){
	try:
		ip_is = False
		result = stream["ipdb"].lookup(ip).split('	')[0]
		if result not in ["局域网","本地链路","共享地址","本机地址","保留地址"]:
			ip_is = True
	except:
		ip_is = False
	return ip_is
}
xlink_uuid =>(x){
	return str(time.time_ns())
}
#需要额外引入的包
imports =>{
	import sys
	import gc
	import base64
	from stream_official_1119_sw import * 
	from un_file import *
	from copy import deepcopy
	from pyipip import IPIPDatabase
}
