#LastModifyDate:　2024-03-26T16:34:32    Author:   rzc
#LastModifyDate:　2024-03-26T16:24:56    Author:   rzc
#LastModifyDate:　2024-03-26T15:16:14    Author:   rzc
#LastModifyDate:　2024-03-26T15:15:31    Author:   rzc
#LastModifyDate:　2024-03-26T11:35:06    Author:   rzc
#LastModifyDate:　2024-03-25T17:41:11    Author:   rzc
#LastModifyDate:　2024-03-25T17:27:09    Author:   rzc
#LastModifyDate:　2024-03-25T17:25:54    Author:   rzc
#LastModifyDate:　2024-03-25T15:56:27    Author:   rzc
#LastModifyDate:　2024-03-25T09:34:37    Author:   rzc
#LastModifyDate:　2024-03-22T16:51:29    Author:   rzc
#xlink脚本
#file: intelligent_idf_string.xlk
#name: 智能识别字符串信息
#描述： 从字符串信息中标识出来数据,并根据形成的规则对数据进行精准识别
#创建时间: 2024-03-21T17:16:51.289137

#查看流计算服务
#a = @udf FBI.x_finder3_list

#启动
#a = @udf FBI.x_finder3_start with intelligent_idf_string

#停止
#a = @udf FBI.x_finder3_stop with intelligent_idf_string

#查询错误日志
#a = load ssdb by ssdb0 query qrange,X_log:intelligent_idf_string,0,1000

#查看xlink内部信息, 每５秒更新
#在对象查看器里输入　printf::intelligent_idf_string

#断点调试
#debug_on(1)


#初始化
init => {
	stream["meta_name"] = "智能识别字符串信息"
	stream["meta_desc"] = "从字符串信息中标识出来数据,并根据形成的规则对数据进行精准识别"
	stream["source"]= {"unix_udp":"/tmp/o_rules"}
	
	stream["st"]["st_10s"]={"times":10,"fun":"print10"}
	stream["st"]["st_120s"]={"times":120,"fun":"send120"}
	#自定义的统计变量
	stream["count"] = 0
	stream["count-10"] = 0
	stream["rules"] = load_pkl("/data/xlink/intell_rules.pkl")
}


#事件处理函数
events => {
	
	http = o.get("http")
	http_method = http.get("http_method")
	dest_ip = o.get("dest_ip")
	dest_port = o.get("dest_port")
	status = http.get("status")
	request_headers = http.get("request_headers")
	response_headers = http.get("response_headers")
	http_response_body = o.get("http_response_body")
	http_request_body = o.get("http_request_body")
	uri = http.get("url")
	if "?" in uri:
		uri = uri.split("?")[0]
	else:
		uri = uri
	urlc = o.get("url_c")
	url = o.get("url")
	
	
	app = o.get("app")
	parameter = o.get("parameter","")
	key = f"Method:{http_method}, App:{app},DestIP:{dest_ip}, DestPort:{dest_port}, Status:{status}"
	
	req_headers = header_handle(http)
	if key in stream["rules"]:
		rules_data = stream["rules"][key]
		if uri in rules_data["urls"]:
		 # 通过这两层判断 才能进行下面操作
			imp_rules = rules_data["rule"]
			 # 数据存储
			data_storage = {}
			for ch_name, t_rules in imp_rules.items():
				# 修改将rules规则改为 列表
				for rules in t_rules:
					for http_pos, pos_rules in rules.items():
						if http_pos == "request_headers":
							data_storage = headers_exract(ch_name, pos_rules, req_headers, data_storage)
						if http_pos == "parameter":
							pos="参数"
							data_storage = par_body(ch_name, pos_rules, parameter, data_storage,pos)
						if http_pos == "request_body":
							pos="请求体"
							data_storage = par_body(ch_name, pos_rules, http_request_body, data_storage,pos)
			if url=="http://100.78.1.125/ebus/00000000000_nw_dzfpfwpt/SJCS_FPJF_ZJ_MRJK":
				printf("da",data_storage)
				#printf("oo",o)
			if data_storage:
				printf("data",data_storage)
				
				
				stream["count"] +=1
				a = {"time":o.get("timestamp"),"id":xlink_uuid(0),"app":app,"url":urlc,"dest_ip":dest_ip,"dest_port":str(dest_port),"parameter":parameter,"request_body":http_request_body,"response_body":http_response_body,"request_headers":req_headers,"response_headers":response_headers,'account_info':data_storage}
				
				to_unix_udp(a,"/tmp/storages")
				
}


#系统定时函数
print10 => {
	printf("总数","%s==sum==%d"%(st,stream["count"]))
	

}

send120 => {
	
	rules = load_pkl("/data/xlink/intell_rules.pkl")
	stream["rules"] = rules
}
xlink_uuid =>(x){
	return str(time.time_ns())
}
par_body =>(ch_name, pos_rules, data_source, data_storage,pos){
	# 获取偏移量
	start_offset = pos_rules["start"].get("offset_pos",0)
	end_offset = pos_rules["end"].get("offset_pos",0)
	# pos_rules 为 {start:{},end:{}}
	start_str = pos_rules["start"]["str"]
	end_str = pos_rules["end"]["str"]
	# 根据两者信息 从数据中提取出重要信息
	start_pos = data_source.find(start_str) + len(start_str)
	end_pos = data_source.find(end_str, start_pos)
	if start_pos != -1 and end_pos != -1:
		current_start = start_pos + start_offset
		current_end = end_pos - end_offset
		res = data_source[current_start:current_end].strip()
		
		if res !="":
			data_storage.setdefault(pos,{}).setdefault(ch_name, []).append(res)
	return data_storage
}
headers_exract =>(ch_name, pos_rules, request_headers, data_storage){
	for key, rule in pos_rules.items():
		for item in request_headers:
			if item["name"].lower() == key.lower():
				# 获取偏移量
				start_offset = rule["start"].get("offset_pos",0)
				end_offset = rule["end"].get("offset_pos",0)
				# 如果相等，就开始让规则从该数据中取出重要信息
				start_str = rule["start"]["str"]
				end_str = rule["end"]["str"]
				# 根据两者信息 从数据中提取出重要信息
				start_pos = item["value"].find(start_str) + len(start_str)
				end_pos = item["value"].find(end_str, start_pos)
				# 如果找到了起始字符串和结束字符串
				if start_pos != -1 and end_pos != -1:
					current_start = start_pos + start_offset
					current_end = end_pos - end_offset
					res = item["value"][current_start:current_end].strip()
					
					if res !="":
						data_storage.setdefault("请求头",{}).setdefault(ch_name, []).append(res)
						continue
	return data_storage
}
header_handle =>(http){
	req_headers=[]
	if "request_headers" in http:
		for item in http["request_headers"]:
			ii={}
			for k,v in item.items():
				ii[k]=unquote(v)
			req_headers.append(ii)
	return req_headers
}

unquote =>(value){
	#if "%" in value:
	if value.find("%") != -1:
		return unquote2(value)
	return value
}
#需要额外引入的包
imports =>{
	import sys
	import gc
	import base64
	from mondic import *
	from urllib.parse import unquote as unquote2
}
