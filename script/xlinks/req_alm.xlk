#LastModifyDate:　2023-12-28T15:43:40.797255    Author:   superFBI
#LastModifyDate:　2023-12-28T10:27:14.766477    Author:   superFBI
#LastModifyDate:　2023-09-01T14:58:45.648994    Author:   superFBI
#LastModifyDate:　2023-08-08T18:34:31.026938    Author:   pjb
#LastModifyDate:　2023-07-31T14:18:09.048914    Author:   pjb
#LastModifyDate:　2023-07-31T14:13:11.331734    Author:   pjb
#LastModifyDate:　2023-06-15T11:04:45.277850    Author:   rzc
#LastModifyDate:　2023-06-15T10:59:55.422008    Author:   superFBI
#LastModifyDate:　2023-04-11T16:49:54.058480    Author:   rzc
#LastModifyDate:　2023-04-11T16:44:51.631416    Author:   rzc
#xlink脚本
#file: req_alm.xlk
#name: 请求异常告警进行存储
#描述： 从redis中取出数据存储请求异常告警的数据

#查看流计算服务
#a = @udf FBI.x_finder3_list

#启动
#a = @udf FBI.x_finder3_start with req_alm

#停止
#a = @udf FBI.x_finder3_stop with req_alm

#查询错误日志
#a = load ssdb by ssdb0 query qrange,X_log:req_alm,0,1000

#查看xlink内部信息, 每５秒更新
#在对象查看器里输入　printf::req_alm

#断点调试
#debug_on(1)


#初始化
init => {
	stream["meta_name"] = "请求异常告警进行存储"
	stream["meta_desc"] = "从redis中取出数据存储请求异常告警的数据"
	a = load_ssdb_kv("setting")
	stream["redis_link"] = a["kfk"]["redis"]["addr_r"]
	stream["ckh_link"] = a["kfk"]["data"]["addr_c"]
	#stream["source"]= {"link":stream["redis_link"]+":6380","topic":"stat_req_alm","redis":"list","topics":["api_data"]}
	stream["source"]= {"unix_udp":"/tmp/api_data_req_alm"}
	stream["CKH"] = CKH_Client(host=stream["ckh_link"],port=19000,user="default",password="client")
	stream["st"]["st_10s"]={"times":10,"fun":"print10"}
	pool["stat_req_alm"] = []
	pool["api_data"] = []
}


#事件处理函数
events => {
	api_type = o.get("api_type")
	status2 = o.get("status2")
	#if topic=="api_data":
	if api_type or api_type != None:
		o["api_type"]=int(o["api_type"])
		o["first_time"]=str(o["first_time"])
		o["last_time"]=str(o["last_time"])
		#o["timestamp"] = iso_to_datetime(o["timestamp"])
		to_pool("api_data",o)
	#if topic == "stat_req_alm":
	if status2 or status2=="":
		o["timestamp"] = iso_to_datetime(o["timestamp"])
		to_pool("stat_req_alm",o)
		#printf("stat_req_alm",pool["stat_req_alm"])
}

#系统定时函数
print10 => {
	store_ckh(pool["stat_req_alm"],"stat_req_alm")
	store_ckh(pool["api_data"],"merge_urls")
}

#窗口函数，使用FBI的原语
flow => stw{

	df2 = group df by dest_ip agg count
	df3 = @udf df by udf0.df_sum
	store df2 to ssdb by ssdb0 with DF:agg=>@k
    store df3 to ssdb by ssdb0 with DF:sum=>@k    
    @udf flow by CRUD.save_table with (msyql,df)
	assert df by df.index.size >0 as xlink to 调度成功[df.index.size] with 调度失败!
}

#窗口函数，使用FBI的原语
http => stw{
	df2 = group df by dest_ip agg count
	df3 = @udf df by udf0.df_sum
	store df2 to ssdb by ssdb0 with DF:agg=>@k
    store df3 to ssdb by ssdb0 with DF:sum=>@k
	t2 = @sdf format_timestamp with (@k,"%Y-%m-%dT%H:%M:%S")
	#调试语句
	assert True as xlink to 调度成功[$t2] with 调度失败!
}

#自定义批处理函数，使用FBI语句块, 可以在系统定时函数中调用
#使用push_arrays_to_df函数生成df,在语句块中使用
#如: push_arrays_to_df(table,"flow")
save => fbi{
	#@udf flow by CRUD.save_table with (msyql,flow_info)
	drop flow
}

#自定义python函数，必须有参数,可以在初始化函数，事件处理函数，和定时函数中使用
ss => (d1,d2,d3){
	return d1+d2+d3
}


#克隆一个新事件,创建一个新的变量，并返回
clone_event =>(o){
	e={}
	e["timestamp"]= o["timestamp"]
	e["src_ip"]= o["src_ip"]
	e["dest_ip"]= o["dest_ip"]
	e["dest_port"]= o["dest_port"]
	return e
}

#base64字符串的解码,处理被截断的情况
base64_decode =>(x){
	try:
		a =  base64.b64decode(x).decode("utf-8")
	except Exception as e:
		a = base64.b64decode(x)[0:e.start].decode("utf-8")
	return a
}

#需要额外引入的包
imports =>{
	import sys
	import gc
	import base64
}
